{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import re\n",
        "import copy"
      ],
      "metadata": {
        "id": "LrucLlh3Hc3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604751ee-fbf0-47c2-a1ee-5953a15882e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/510.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Easy-CoT Datasets"
      ],
      "metadata": {
        "id": "b17kIfWy7wZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune-CoT Base Dataset\n",
        "Courtesy of https://github.com/itsnamgyu/reasoning-teacher, reasoning chains generated with on the default teacher model text-davinci-002 are avaliable to use as base dataset."
      ],
      "metadata": {
        "id": "3x99OieuGp7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# format: {'index':[{'sample_index', 'completion_index', 'question', 'anwser','reasoning_prompt', 'reasoning_completion','prompt','completion'}]}\n",
        "coinFlip = load_json(dataset='coin_flip.json')['data']\n",
        "lastLetter = load_json(dataset='last_letter.json')['data']\n",
        "commonSenseQA = load_json(dataset='commonsense_qa.json')['data']\n",
        "strategyQA = load_json(dataset='strategy_qa.json')['data']\n",
        "gsm8k = load_json(dataset='gsm8k.json')['data']\n",
        "multiArith = load_json(dataset='multiarith.json')['data']"
      ],
      "metadata": {
        "id": "DpbaaezgGm9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Easy-CoT Dataset (Rationale and Demo)\n",
        "Code adapted from https://github.com/amazon-science/auto-cot/blob/main/run_demo.py"
      ],
      "metadata": {
        "id": "2BboyQjAHeSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "ZqKfF78pISXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "\n",
        "task = 'gsm8k'    # choices=[\"gsm8k\", \"commonsense_qa\",\"multiarith\", \"strategy_qa\", \"coin_flip\", \"last_letter\"]\n",
        "max_ra_len = 5    # maximum reasoning chain length\n",
        "encoder = 'all-MiniLM-L6-v2' # sentence encoder for clustering\n",
        "sampling = 'center'          # whether to sample the cluster center first\n",
        "random_seed = 129\n",
        "silent = True\n",
        "\n",
        "def run_auto_cot(dataset, task='gsm8k', save_dir='easy_cot/', max_ra_len=5,random_seed = 192,encoder = 'all-MiniLM-L6-v2',sampling = 'center'):\n",
        "  '''apply auto cot on base dataset, output easy_cot dataset'''\n",
        "\n",
        "  encoder = SentenceTransformer(encoder)\n",
        "\n",
        "  if task == \"last_letter\":\n",
        "      max_ra_len = 7\n",
        "      num_clusters = 4\n",
        "  elif task == \"commonsens_qa\":\n",
        "      num_clusters = 7\n",
        "  elif task == \"strategy_qa\":\n",
        "      num_clusters = 6\n",
        "  else:\n",
        "      num_clusters = 8\n",
        "\n",
        "  corpus = []\n",
        "  question = []\n",
        "  rationale = []\n",
        "  answer = []\n",
        "\n",
        "  for idx in list(dataset.keys()):\n",
        "    sample = dataset[idx][0]\n",
        "    q = 'Q: ' + sample['question'] + '\\nA:'\n",
        "    a = sample['answer']\n",
        "    r = sample['reasoning_completion']\n",
        "\n",
        "    corpus.append(q)\n",
        "    question.append(q)\n",
        "    rationale.append(r)\n",
        "    answer.append(a)\n",
        "\n",
        "  # run auto-cot\n",
        "  corpus_embeddings = encoder.encode(corpus)\n",
        "  clustering_model = KMeans(n_clusters=num_clusters, random_state=random_seed, n_init='auto')\n",
        "  clustering_model.fit(corpus_embeddings)\n",
        "  cluster_assignment = clustering_model.labels_\n",
        "  clustered_sentences = [[] for i in range(num_clusters)]\n",
        "  dist = clustering_model.transform(corpus_embeddings)\n",
        "  clustered_dists = [[] for i in range(num_clusters)]\n",
        "  clustered_idx = [[] for i in range(num_clusters)]\n",
        "\n",
        "  for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "      clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "      clustered_dists[cluster_id].append(dist[sentence_id][cluster_id])\n",
        "      clustered_idx[cluster_id].append(sentence_id)\n",
        "\n",
        "  datas = []\n",
        "  demos = []\n",
        "  get_demo = True\n",
        "\n",
        "  for i in range(len(clustered_dists)):\n",
        "      # print(\"Cluster \", i+1)\n",
        "      tmp = list(map(list, zip(range(len(clustered_dists[i])), clustered_dists[i])))\n",
        "      top_min_dist = sorted(tmp, key=lambda x: x[1], reverse=False)\n",
        "      get_demo = True\n",
        "\n",
        "      for element in top_min_dist:\n",
        "          min_idx = element[0]\n",
        "          c_rationale = rationale[clustered_idx[i][min_idx]].strip()\n",
        "          a = answer[clustered_idx[i][min_idx]].strip()\n",
        "          q = question[clustered_idx[i][min_idx]]\n",
        "          r = c_rationale.replace(\"\\n\\n\", \"\\n\").replace(\"\\n\", \" \").strip()\n",
        "          r = \" \".join(r.split())\n",
        "\n",
        "          p = q[3:-4] + \"###\"\n",
        "          c = i+1\n",
        "\n",
        "          if get_demo and len(question[clustered_idx[i][min_idx]].strip().split()) <= 60 \\\n",
        "              and len(c_rationale.replace(\"\\n\\n\", \"\\n\").split(\"\\n\")) <= max_ra_len and c_rationale[-1] == \".\" and a != \"\":\n",
        "\n",
        "              # demo for icl\n",
        "              d = p + r + \"-->\" + a\n",
        "              demo = {\"demo\": d, \"cluster\": c}\n",
        "              demos.append(demo)\n",
        "              get_demo = False # one demo for each cluster\n",
        "\n",
        "          else:\n",
        "            # data for fine-tuning\n",
        "            data = {\"prompt\": p, \"answer\": r + '-->' + a + '<|endoftext|>', \"cluster\": c}\n",
        "            datas.append(data)\n",
        "\n",
        "  with open(save_dir + 'demos.json', 'w', encoding=\"utf-8\") as write_f:\n",
        "      json.dump(demos, write_f, indent=4, ensure_ascii=False)\n",
        "\n",
        "  with open(save_dir + 'data.json', 'w', encoding=\"utf-8\") as write_f:\n",
        "      json.dump(datas, write_f, indent=4, ensure_ascii=False)\n",
        "\n",
        "  # y_km = clustering_model.fit_predict(corpus_embeddings)\n",
        "  # pca_model = PCA(n_components=2, random_state=random_seed)\n",
        "  # transformed = pca_model.fit_transform(corpus_embeddings)\n",
        "  # centers = pca_model.transform(clustering_model.cluster_centers_)\n",
        "\n",
        "  # plt.scatter(x=transformed[:, 0], y=transformed[:, 1], c=y_km, s=50, cmap=plt.cm.Paired, alpha=0.4)\n",
        "  # plt.scatter(centers[:, 0],centers[:, 1],\n",
        "  #         s=250, marker='*', label='centroids',\n",
        "  #         edgecolor='black',\n",
        "  #         c=np.arange(0,num_clusters),cmap=plt.cm.Paired,)\n",
        "  # plt.xticks([])\n",
        "  # plt.yticks([])\n",
        "  # plt.savefig(save_dir+\".png\", dpi=600)\n",
        "\n"
      ],
      "metadata": {
        "id": "eabtRXKkHhLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_auto_cot(coinFlip, 'coin_flip', 'easy_cot/coinFlip/')\n",
        "run_auto_cot(lastLetter, 'last_letter', 'easy_cot/lastLetter/')\n",
        "run_auto_cot(multiArith, 'multi_arith', 'easy_cot/multiArith/')\n",
        "run_auto_cot(gsm8k, 'gsm8k', 'easy_cot/gsm8k/')\n",
        "run_auto_cot(commonSenseQA, 'commonsense_qa', 'easy_cot/commonSenseQA/')\n",
        "run_auto_cot(strategyQA, 'strategy_qa', 'easy_cot/strategyQA/')"
      ],
      "metadata": {
        "id": "rlHoqtqsIOvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert json files to hugggingface datasets"
      ],
      "metadata": {
        "id": "hTA2fXUoGesF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"json\", data_files=\"easy_cot/multiArith/data.json\")\n",
        "demo = load_dataset(\"json\", data_files=\"easy_cot/multiArith/demos.json\")"
      ],
      "metadata": {
        "id": "K_rv__qCGGDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0]"
      ],
      "metadata": {
        "id": "jFGNqHDnG66i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo['train'][0]"
      ],
      "metadata": {
        "id": "6iSu8DeZGoMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "cl5nnDawOKuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "batch_size = 2\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "sample_every = 100\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# torch Dataset\n",
        "class GPT2Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, max_length=768):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>' + txt['prompt'] + txt['answer'], truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "# helper methods\n",
        "def train_valid_test(task_folder='multiArith/'):\n",
        "  '''split easy-cot data with 8:1:1 ratio'''\n",
        "  raw = load_dataset(\"json\", data_files=\"easy_cot/\" + task_folder + \"data.json\")\n",
        "  data = Dataset.from_pandas(pd.DataFrame(data=raw))\n",
        "  train_test_split = data.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
        "  train = train_test_split['train']\n",
        "  test = train_test_split['test']\n",
        "  valid_test_split = test.train_test_split(test_size=0.5, shuffle=False, seed=42)\n",
        "  valid = valid_test_split['train']\n",
        "  test = valid_test_split['test']\n",
        "  return train['train'], valid['train'], test['train']\n",
        "\n",
        "\n",
        "def save_model(model, tokenizer, output_dir):\n",
        "  if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "  print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  model_to_save.save_pretrained(output_dir)\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "\n",
        "def load_model(output_dir):\n",
        "  model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "  model.to(device)\n",
        "  return model, tokenizer\n",
        "\n",
        "def extract_answer(output, is_generated=False):\n",
        "  if is_generated:\n",
        "    pattern = r'-->(.*)'\n",
        "  else:\n",
        "    pattern = r'-->(.*?)<'\n",
        "  m = re.search(pattern, output)\n",
        "  if m:\n",
        "      return m.group(1)\n",
        "  else:\n",
        "      return None\n",
        "\n",
        "def get_accuracy(model, tokenizer, test_set,tok_lim=50):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for sample in test_set:\n",
        "    prompt = sample['prompt']\n",
        "    answer = extract_answer(sample['answer'])\n",
        "    len_prompt = len(prompt)\n",
        "\n",
        "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "    generated = generated.to(device)\n",
        "\n",
        "    sample_outputs = model.generate(\n",
        "                                    generated,\n",
        "                                    #bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,\n",
        "                                    max_new_tokens=tok_lim,\n",
        "                                    num_return_sequences=1,\n",
        "                                    pad_token_id=tokenizer.eos_token_id\n",
        "                                    )\n",
        "\n",
        "    for i, sample_output in enumerate(sample_outputs):\n",
        "      # print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "      extracted_answer = extract_answer(tokenizer.decode(sample_output, skip_special_tokens=True)[len_prompt:], is_generated=True)\n",
        "      # print(f'extracted: {extracted_answer}, truth: {answer}')\n",
        "\n",
        "      if extracted_answer is not None and extracted_answer.strip() == answer.strip():\n",
        "        correct += 1\n",
        "      total += 1\n",
        "  return correct/total\n",
        "\n",
        "def three_run(model, tokenizer, test_set, tok_lim=50):\n",
        "  avg_accuracy = 0\n",
        "  for _ in range(3):\n",
        "    avg_accuracy += get_accuracy(model, tokenizer, test_set)\n",
        "\n",
        "  avg_accuracy /= 3\n",
        "  print(f'Average accuracy over 3 runs: {avg_accuracy}')\n",
        "\n",
        "def run_test(model, tokenizer, valid, test, tok_lim=50):\n",
        "  print('test--> ', end='')\n",
        "  three_run(model, tokenizer, test, tok_lim=50)\n",
        "  print(\"======== End of Results ========\")"
      ],
      "metadata": {
        "id": "vrHQMc1fpfqu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Fine-tune CoT\n",
        "Training code adapted from https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=gFsCTp_mporB"
      ],
      "metadata": {
        "id": "vAkB8pbl7620"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_model(task_folder='multiArith/', model_dir='./model_saved/'):\n",
        "  '''fine-tune gpt2-small on Easy-CoT data of provided task, save the model in model_dir'''\n",
        "\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "\n",
        "  # data split\n",
        "  train, valid, test = train_valid_test(task_folder)\n",
        "  train = train[:800]\n",
        "  train_dataset = GPT2Dataset(train, tokenizer)\n",
        "  val_dataset = GPT2Dataset(valid, tokenizer)\n",
        "\n",
        "  train_dataloader = DataLoader(\n",
        "              train_dataset,\n",
        "              sampler = RandomSampler(train_dataset),\n",
        "              batch_size = batch_size\n",
        "          )\n",
        "\n",
        "  # load pretrained model and scheduler\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "  model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = learning_rate,\n",
        "                    eps = epsilon\n",
        "                  )\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                              num_warmup_steps = warmup_steps,\n",
        "                                              num_training_steps = total_steps)\n",
        "\n",
        "  # train\n",
        "  def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "  total_t0 = time.time()\n",
        "  training_stats = []\n",
        "  model = model.to(device)\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "\n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      total_train_loss = 0\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_labels = batch[0].to(device)\n",
        "          b_masks = batch[1].to(device)\n",
        "\n",
        "          model.zero_grad()\n",
        "\n",
        "          outputs = model(  b_input_ids,\n",
        "                            labels=b_labels,\n",
        "                            attention_mask = b_masks,\n",
        "                            token_type_ids=None\n",
        "                          )\n",
        "\n",
        "          loss = outputs[0]\n",
        "\n",
        "          batch_loss = loss.item()\n",
        "          total_train_loss += batch_loss\n",
        "\n",
        "          # Get sample every x batches.\n",
        "          if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "              model.train()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          scheduler.step()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "  save_model(model, tokenizer, model_dir)\n",
        "\n",
        "  # test\n",
        "  # run_test(model, tokenizer, valid, test)"
      ],
      "metadata": {
        "id": "OFd1DkuSp7Ld"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_test(task_folder='multiArith/', model_dir='./multiarith_model/'):\n",
        "  model, tokenizer = load_model(model_dir)\n",
        "\n",
        "  # data split\n",
        "  train, valid, test = train_valid_test(task_folder)\n",
        "  train_dataset = GPT2Dataset(train, tokenizer)\n",
        "  val_dataset = GPT2Dataset(valid, tokenizer)\n",
        "\n",
        "  # test\n",
        "  run_test(model, tokenizer, valid, test)"
      ],
      "metadata": {
        "id": "BgrfdvQiLGN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### experiment playground"
      ],
      "metadata": {
        "id": "dv1tvFj0IX97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_model(task_folder='coinFlip/', model_dir='finetuned_model/coinFlip/')"
      ],
      "metadata": {
        "id": "4xecgYv9gKTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Context-agumented Auto-CoT + Easy-CoT ---> full testing pipeline"
      ],
      "metadata": {
        "id": "pIyqnMlbFDHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_all(task_folder='multiArith/', model_dir='/finetuned_model/multiArith',tok_lim=50):\n",
        "\n",
        "    default_model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration).to(device)\n",
        "    default_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
        "    model, tokenizer = load_model(model_dir)\n",
        "\n",
        "    # test split\n",
        "    raw = load_dataset(\"json\", data_files=\"easy_cot/\" + task_folder + \"data.json\")\n",
        "    # test = context-augmented, test_cpy = original prompt\n",
        "    data = Dataset.from_pandas(pd.DataFrame(data=raw))\n",
        "    train_test_split = data.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
        "    test = train_test_split['test']['train']\n",
        "    test_cpy = copy.deepcopy(test)\n",
        "    # load demos\n",
        "    raw = load_dataset(\"json\", data_files=\"easy_cot/\" + task_folder + \"demos.json\")\n",
        "    demos = raw['train']\n",
        "\n",
        "    context = \"\"\n",
        "    for sample in demos:\n",
        "        tmp_str = context + sample['demo'] + \"\\n\"\n",
        "        if len(tmp_str.split()) > 600:\n",
        "            break\n",
        "        context = tmp_str\n",
        "\n",
        "    for sample in test:\n",
        "        sample['prompt'] = context + sample['prompt']\n",
        "\n",
        "    # print(\"\")\n",
        "    print(\"Running Fine-tune-CoT...\")\n",
        "    run_test(model, default_tokenizer, None, test_cpy,)\n",
        "    print(\"Running Auto-CoT...\")\n",
        "    run_test(default_model, default_tokenizer, None, test)\n",
        "    print(\"Running Easy-CoT...\")\n",
        "    run_test(model, default_tokenizer, None, test)\n"
      ],
      "metadata": {
        "id": "EohVO_NnSNoj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### experiment playground"
      ],
      "metadata": {
        "id": "5OQV0erYzqCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_all('coinFlip/','finetuned_model/coinFlip/',tok_lim=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCzBHTl3QMDl",
        "outputId": "8a501abc-7473-4415-f09e-678c330dffb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fine-tune-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.09090909090909091\n",
            "======== End of Results ========\n",
            "Running Auto-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.010101010101010102\n",
            "======== End of Results ========\n",
            "Running Easy-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.5757575757575758\n",
            "======== End of Results ========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_all('lastLetter/','finetuned_model/lastLetter/',tok_lim=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMQL4V8XRzz_",
        "outputId": "814ae2c5-7bc6-4235-ea4d-88fd3fd3fe7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fine-tune-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.0\n",
            "======== End of Results ========\n",
            "Running Auto-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.0\n",
            "======== End of Results ========\n",
            "Running Easy-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.0\n",
            "======== End of Results ========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_all('gsm8k/','finetuned_model/gsm8k/',tok_lim=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFdpF1z82H-h",
        "outputId": "94940ade-b45b-4c6e-a6b4-9d79767fc9d2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fine-tune-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.0\n",
            "======== End of Results ========\n",
            "Running Auto-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.0\n",
            "======== End of Results ========\n",
            "Running Easy-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.007633587786259542\n",
            "======== End of Results ========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_all('multiArith/','finetuned_model/multiArith/',tok_lim=50)"
      ],
      "metadata": {
        "id": "XEyjhIQTR4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f3a8fa-ce5b-4153-85ec-283960bcff98"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fine-tune-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.008403361344537815\n",
            "======== End of Results ========\n",
            "Running Auto-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.008403361344537815\n",
            "======== End of Results ========\n",
            "Running Easy-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.025210084033613446\n",
            "======== End of Results ========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_all('commonSenseQA/','finetuned_model/commonSenseQA/',tok_lim=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a31IA0LHvYMn",
        "outputId": "fbc1b202-09af-4be8-805b-33acbc4af91b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fine-tune-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.05508474576271186\n",
            "======== End of Results ========\n",
            "Running Auto-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.03389830508474576\n",
            "======== End of Results ========\n",
            "Running Easy-CoT...\n",
            "\n",
            "test--> Average accuracy over 3 runs: 0.1271186440677966\n",
            "======== End of Results ========\n"
          ]
        }
      ]
    }
  ]
}