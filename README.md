# Easy-CoT: Extensible Dataset for Diverse CoT Reasoning On Small Datasets




## Directories
### code/
The easy_cot.ipynb notebook has the following methods avaliable for use: 
- run_auto_cot(dataset, task, save_dir, *hyperparams): apply auto-cot on base dataset to generate json file of demonstrations and dump in save_dir.
- finetune_model(

### easy_cot/
Contains our main Easy-CoT dataset. See generation process in paper. Each subdirectory of easy_cot has a name corresponding to the base dataset that it was generated from, and contains two files: data.json (containing output of fine-tune-cot applied on base dataset) and demos.json (containing output of auto-cot applied on data.json).

### finetuned_model/
Contains the link to all fine-tuned models from our experiment. There are six models in total, one for each base dataset.

### datasets/
Contains the six base datasets on complex reasoning tasks used to generate our easy_cot dataset.

- fine_tune_cot/: completed data generated by teacher model in fine-tune-cot, courtesy of [Ho et al.](https://github.com/itsnamgyu/reasoning-teacher)

- zero_shot_cot/: raw data for complex reasoning task benchmarks, courtesy of [Kojima et al.](https://github.com/kojima-takeshi188/zero_shot_cot/tree/main/dataset)

